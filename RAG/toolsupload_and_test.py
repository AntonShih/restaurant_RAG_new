import os
import json
import sys
from dotenv import load_dotenv
from argparse import ArgumentParser

from RAG.core.embedding import embed_faq_list_batch, load_api_key
from RAG.core.formatting import format_for_pinecone
from RAG.core.compare import search_similar_faqs
from pinecone import Pinecone


def load_environment():
    """è¼‰å…¥ç’°å¢ƒè®Šæ•¸èˆ‡åˆå§‹åŒ– API"""
    load_dotenv()
    load_api_key()

    api_key = os.getenv("PINECONE_API_KEY")
    index_name = os.getenv("PINECONE_INDEX_NAME")
    namespace = os.getenv("PINECONE_NAMESPACE")

    try:
        index = Pinecone(api_key=api_key).Index(index_name)
        print(f"âœ… æˆåŠŸé€£æ¥åˆ° Pinecone ç´¢å¼•: {index_name}")
        return index, namespace
    except Exception as e:
        print(f"âŒ é€£æ¥ Pinecone å¤±æ•—: {str(e)}")
        sys.exit(1)


def process_faq_file(path="data/sop.json"):
    """è®€å– JSON FAQ æª”æ¡ˆä¸¦å»é‡ï¼Œè³‡æ–™æ¸…æ´—"""
    full_path = os.path.abspath(os.path.join(os.getcwd(), path))

    try:
        with open(full_path, "r", encoding="utf-8") as f:
            raw_faqs = json.load(f)
    except Exception as e:
        print(f"âŒ ç„¡æ³•è®€å–æª”æ¡ˆ {full_path}: {e}")
        return []

    seen = set()
    result = []
    for faq in raw_faqs:
        q = faq.get("question")
        if q and q not in seen:
            seen.add(q)
            result.append(faq)

    print(f"ğŸ“Š å…±è®€å– {len(raw_faqs)} ç­†ï¼Œå»é‡å¾Œå‰© {len(result)} ç­† FAQ")
    return result


def get_existing_vector_info(index, namespace):
    """ä½¿ç”¨ fetch API æ“·å–ç›®å‰æ‰€æœ‰å‘é‡ ID èˆ‡å°æ‡‰å•é¡Œ"""
    existing_ids, existing_questions = set(), set()

    try:
        stats = index.describe_index_stats()
        count = stats.get("namespaces", {}).get(namespace, {}).get("vector_count")
        if count == 0:
            return existing_ids, existing_questions

        fetch_ids = [f"faq_{i+1}" for i in range(count)]
        fetched = index.fetch(ids=fetch_ids, namespace=namespace)

        for vector_id, record in fetched.vectors.items():
            existing_ids.add(vector_id)
            metadata = record.metadata
            if metadata and "question" in metadata:
                existing_questions.add(metadata["question"])

    except Exception as e:
        print(f"âŒ ä½¿ç”¨ fetch å–å¾—å‘é‡è³‡è¨Šå¤±æ•—ï¼š{e}")

    return existing_ids, existing_questions



def upload_to_vector_db(index, faqs, namespace, batch_size=100):
    print("ğŸ” æª¢æŸ¥å‘é‡è³‡æ–™åº«...")
    existing_ids, existing_questions = get_existing_vector_info(index, namespace)
    vectors = format_for_pinecone(faqs)

    new_vectors = [v for v in vectors if v["id"] not in existing_ids and v["metadata"]["question"] not in existing_questions]
    print(f"ğŸ“¦ éæ¿¾å¾Œå‰© {len(new_vectors)}/{len(vectors)} ç­†å‘é‡è¦ä¸Šå‚³")

    if not new_vectors:
        print("âš ï¸ æ²’æœ‰æ–°è³‡æ–™éœ€è¦ä¸Šå‚³")
        return True

    try:
        for i in range(0, len(new_vectors), batch_size):
            batch = new_vectors[i:i + batch_size]
            index.upsert(vectors=batch, namespace=namespace)
        print("âœ… å‘é‡ä¸Šå‚³å®Œæˆ")
        return True
    except Exception as e:
        print(f"âŒ ä¸Šå‚³å¤±æ•—ï¼š{e}")
        return False


def interactive_mode(index, namespace):
    print("\nğŸ¤– é¤é£²æ¥­ FAQ åŠ©æ‰‹å·²å•Ÿå‹•ï¼Œè¼¸å…¥ 'exit' é›¢é–‹\n")
    while True:
        q = input("è«‹è¼¸å…¥å•é¡Œï¼š\n> ").strip()
        if q.lower() in ["exit", "quit", "bye", "é›¢é–‹"]:
            print("ğŸ‘‹ æ„Ÿè¬ä½¿ç”¨ï¼Œå†è¦‹ï¼")
            break

        print("\nğŸ” æœå°‹ä¸­...")
        results = search_similar_faqs(query=q)

        if not results:
            print("â“ æ‰¾ä¸åˆ°ç›¸é—œè³‡æ–™ï¼Œè«‹æ”¹ç”¨ä¸åŒæ–¹å¼è©¢å•ã€‚\n")
            continue

        print("ğŸ“ æœ€ç›¸è¿‘ FAQï¼š\n")
        for i, r in enumerate(results, 1):
            meta = r["metadata"]
            print(f"{i}. [{meta.get('category', 'æœªåˆ†é¡')}] {meta.get('question')}\n   ç­”ï¼š{meta.get('answer')}\n   ç›¸ä¼¼åº¦ï¼š{round(r['score'], 4)}\n")


def main():
    parser = ArgumentParser()
    parser.add_argument("--upload", action="store_true", help="æ˜¯å¦é‡æ–°ä¸Šå‚³ FAQ")
    parser.add_argument("--path", type=str, default="data/sop.json", help="FAQ JSON æª”æ¡ˆè·¯å¾‘")
    args = parser.parse_args()

    print("ğŸš€ é¤é£²æ¥­ FAQ RAG ç³»çµ±å•Ÿå‹•ä¸­...")
    index, namespace = load_environment()

    if args.upload:
        faqs = process_faq_file(args.path)
        if not faqs:
            print("âŒ ç„¡ FAQ è³‡æ–™ï¼Œç¨‹åºä¸­æ­¢")
            return

        print("ğŸ” æª¢æŸ¥å‘é‡è³‡æ–™åº«æ˜¯å¦å·²æœ‰ç›¸åŒå•é¡Œ...")
        existing_ids, existing_questions = get_existing_vector_info(index, namespace)

        # éæ¿¾å‡ºæ–°å•é¡Œï¼ˆé¿å…æµªè²» OpenAI embeddingï¼‰
        new_faqs = [f for f in faqs if f["question"] not in existing_questions]
        print(f"ğŸ†• å…±ç™¼ç¾ {len(new_faqs)} ç­†æ–°å•é¡Œï¼ˆå°‡é€å…¥ OpenAI åµŒå…¥ï¼‰")

        if not new_faqs:
            print("âš ï¸ ç„¡éœ€åµŒå…¥ï¼Œæ‰€æœ‰è³‡æ–™çš†å·²å­˜åœ¨")
        else:
            print("ğŸ§  æ­£åœ¨ç”Ÿæˆå‘é‡åµŒå…¥...")
            embedded = embed_faq_list_batch(new_faqs)
            embedded = [f for f in embedded if "embedding" in f]

            if not upload_to_vector_db(index, embedded, namespace):
                print("âŒ ä¸Šå‚³å¤±æ•—")
                return
    else:
        interactive_mode(index, namespace)


if __name__ == "__main__":
    main()
