import openai
from pinecone import Pinecone
from dotenv import load_dotenv
import os
import json

# è¼‰å…¥ç’°å¢ƒè®Šæ•¸èˆ‡åˆå§‹åŒ–
load_dotenv()
openai.api_key = os.getenv("OPENAI_API_KEY")
pc = Pinecone(api_key=os.getenv("PINECONE_API_KEY"))
index = pc.Index(os.getenv("PINECONE_INDEX_NAME"))
namespace = os.getenv("PINECONE_NAMESPACE")
# namespace ä¸æ˜¯ã€Œæ¨™ç±¤åˆ†é¡ã€ï¼Œè€Œæ˜¯ã€Œè³‡æ–™åˆ†å€ã€çš„æ¦‚å¿µã€‚
# ä½ å¯ä»¥æŠŠå®ƒæƒ³æˆï¼šè³‡æ–™åº«ä¸­çš„ã€Œç¨ç«‹è³‡æ–™è¡¨ã€ï¼Œä¸æ˜¯è³‡æ–™åˆ—ä¸­çš„ã€Œæ¬„ä½ã€æˆ–ã€Œæ¨™ç±¤ã€ã€‚

def get_embedding(text):
    """
    å‘¼å« OpenAI API å°‡è¼¸å…¥æ–‡å­—è½‰æ›æˆå‘é‡
    returnå›ä¾†çš„è³‡æ–™çµæ§‹
    {"object": "list",
    "data": [{
        "embedding": [0.0123, 0.0042, ..., -0.0019],
        "index": 0,
        "object": "embedding"}],
    "model": "text-embedding-3-small",
    "object": "list",
    "usage": {
    "prompt_tokens": 9,
    "total_tokens": 9}}
    """
    response = openai.embeddings.create(
        input=text,
        model="text-embedding-3-small"
    )
    return response.data[0].embedding

# æª¢æŸ¥openaiæ ¼å¼ ç‰©ä»¶è½‰json ensure_ascii ä¿ç•™ä¸­æ–‡
def print_embedding_response(text):
    response = openai.embeddings.create(
        input=text,
        model="text-embedding-3-small"
    )
    print(json.dumps(response.to_dict(), indent=2, ensure_ascii=False))

# æª¢æŸ¥pinecone

def debug_pinecone_response(response):
    print("å›å‚³å‹åˆ¥ï¼š", type(response))
    print("å®Œæ•´è³‡æ–™å…§å®¹ï¼š\n")
    print(json.dumps(response.to_dict(), indent=2, ensure_ascii=False))

   

def search_similar_faqs(query, top_k=3):
    """æŸ¥è©¢æœ€ç›¸ä¼¼ FAQ å‘é‡"""
    query_vector = get_embedding(query)
    result = index.query(
        vector=query_vector,
        top_k=top_k,
        include_metadata=True,
        namespace=namespace
    )
    # print(type(result))  # è¼¸å‡ºï¼š<class 'dict'>
    # print(dir(result))  # çœ‹çœ‹æœ‰å“ªäº›å±¬æ€§èˆ‡æ–¹æ³•

    return result["matches"]


if __name__ == "__main__":
    user_input = input("è«‹è¼¸å…¥ä½ çš„å•é¡Œï¼š\n> ")
    results = search_similar_faqs(user_input)
    
    # # print_embedding_response(user_input)
    # query_vector = get_embedding(user_input)
    # full_response = index.query(
    # vector=query_vector,
    # top_k=3,
    # include_metadata=True,
    # namespace=namespace
    # )

    # # å°å‡ºå®Œæ•´ Pinecone å›å‚³è³‡æ–™
    # debug_pinecone_response(full_response)

    print("\nğŸ” æœ€ç›¸è¿‘çš„ FAQï¼š\n")
    for i, r in enumerate(results, 1):
        meta = r["metadata"]
        print(f"{i}. [{meta['category']}] {meta['question']}")
        print(f"   ç­”ï¼š{meta['answer']}")
        print(f"   ç›¸ä¼¼åº¦ï¼š{round(r['score'], 4)}\n")