from compare import search_similar_faqs
import openai
import os
import sys
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), "..")))
from line_bot.models import get_user_role

openai.api_key = os.getenv("OPENAI_API_KEY")


def answer_query_secure(query, user_id):
    """å®‰å…¨ç‰ˆæŸ¥è©¢ï¼šæŸ¥ top3ï¼Œæ¬Šé™éæ¿¾å¾Œäº¤ç”± LLM åˆ¤æ–·"""
    user = get_user_role(user_id)
    user_level = user.get("access_level", 0) if user else 0

    #å¦‚æœç¬¦åˆç•™ä¸‹ä¾† 
    matches = search_similar_faqs(query, top_k=3)
    filtered = [m for m in matches if m["metadata"].get("access_level") <= user_level]

    # âœ… DEBUG print å€å¡Š
    print("ğŸ” [DEBUG] ä½¿ç”¨è€…å•é¡Œï¼š", query)
    print("ğŸ‘¤ [DEBUG] ä½¿ç”¨è€… IDï¼š", user_id, "è·ç­‰ç­‰ç´šï¼š", user_level)

    print("ğŸ“¥ Top3 FAQ:")
    for m in matches:
        meta = m["metadata"]
        print(f" - ({meta.get('access_level')}) {meta['question']}")

    print("ğŸ”’ Filtered FAQï¼ˆç¬¦åˆè·ç­‰ï¼‰:")
    for m in filtered:
        meta = m["metadata"]
        print(f" âœ… ({meta.get('access_level')}) {meta['question']}")

    if not filtered:
        return "âš ï¸ æŠ±æ­‰ï¼Œæ‚¨ç›®å‰çš„è·ç­‰ç„¡æ³•æŸ¥é–±ç›¸é—œè³‡æ–™ï¼Œè«‹æ´½è©¢ä¸Šç´šæˆ–ç®¡ç†è€…ã€‚"

    return generate_judged_answer(query, filtered)

def generate_judged_answer(query, filtered_matches):
    """è«‹ LLM æ ¹æ“šéæ¿¾å¾Œçš„å…§å®¹ç”Ÿæˆå›è¦†æˆ–æ‹’ç­”"""
    context = ""
    # é€™é‚Šçš„1æ˜¯enumerateå¾1è™Ÿé–‹å§‹contextåªçµ¦ä»–å•é¡Œè·Ÿç­”æ¡ˆè€Œå·²ï¼Œèªæ„å®Œæ•´
    for i, m in enumerate(filtered_matches, 1):
        meta = m["metadata"]
        context += f"{i}. å•é¡Œ: {meta['question']}\n   å›ç­”: {meta['answer']}\n"

    print("\nğŸ“‹ [DEBUG] æœ€çµ‚å¯ç”¨ FAQï¼š")
    print(context)

    messages = [
        {
            "role": "system",
            "content": (
                "ä½ æ˜¯ä¸€ä½é¤é£² FAQ åŠ©ç†ã€‚\n"
                "è«‹ä¾ç…§ä»¥ä¸‹æµç¨‹è™•ç†ä½¿ç”¨è€…çš„å•é¡Œï¼š\n"
                "\n"
                "Step 1ï¼šé–±è®€ä»¥ä¸‹ FAQï¼Œåˆ¤æ–·æ˜¯å¦å¯ä»¥æ ¹æ“šå…§å®¹å›ç­”ã€‚\n"
                "- è‹¥ FAQ ä¸­çš„èªæ„å¯æ¸…æ¥šæ”¯æ’å›ç­”ï¼Œå³ä½¿æ–‡å­—ä¸å®Œå…¨ç›¸åŒï¼Œä¹Ÿå¯é€²è¡Œå›è¦†ã€‚\n"
                "- å›ç­”åƒ…é™æ–¼ FAQ æ‰€æ¶µè“‹çš„å…§å®¹ï¼Œç¦æ­¢å¼•å…¥é¡å¤–å¸¸è­˜ã€‚\n"
                "- è‹¥ç¢ºå¯¦ç„¡è³‡æ–™å¯åƒè€ƒï¼Œè«‹å›ï¼šã€Œç›®å‰ç„¡æ³•æä¾›æº–ç¢ºç­”æ¡ˆã€ã€‚\n"
                "\n"
                "Step 2ï¼šè‹¥ FAQ å¯å›æ‡‰ï¼Œè«‹ç¢ºèªè©²å•é¡Œæ˜¯å¦å±¬æ–¼é¤é£²æ¥­å¸¸è¦‹å·¥ä½œæˆ–è¡Œæ”¿å·¥ä½œè™•ç†ç¯„ç–‡ã€‚\n"
                "- è‹¥éƒ½ä¸æ˜¯ï¼Œè«‹å›ï¼šã€Œé€™ä¸æ˜¯æˆ‘èƒ½è™•ç†çš„ç¯„ç–‡å“¦ï½ã€ã€‚\n"
                "\n"
                "âš ï¸ ç¦æ­¢ä½¿ç”¨ä»»ä½•é FAQ çš„çŸ¥è­˜ã€‚å³ä½¿ä½ çŸ¥é“æ­£ç¢ºç­”æ¡ˆï¼Œåªè¦ FAQ æ²’å¯«ï¼Œä¹Ÿä¸èƒ½èªªã€‚\n"
                "âŒ ä¸å¾—åŠ å…¥çµèªï¼Œä¸å¾—èªªé¡å¤–é—œå¿ƒã€Œæ­¡è¿å†æ¬¡æå•ã€ã€ã€Œæœ‰å…¶ä»–å•é¡Œè«‹è©¢å•ã€ã€Œå¸Œæœ›å¯ä»¥å¹«ä½ è§£æ±ºå•é¡Œã€ç­‰å¥å­ã€‚"
            )
        },
        {
            "role": "user",
            "content": f"ä½¿ç”¨è€…å•ï¼šã€Œ{query}ã€\nä»¥ä¸‹æ˜¯ä»–æœ‰æ¬Šé™æŸ¥é–±çš„ FAQï¼š\n{context}"
        }
    ]

    print("\nğŸ“¤ [DEBUG] å‚³é€çµ¦ GPT çš„ Promptï¼š")
    print(messages[1]["content"])

    completion = openai.chat.completions.create(
        model="gpt-3.5-turbo",
        messages=messages,
        max_tokens=300,
        temperature=0.1
    )

    reply = completion.choices[0].message.content.strip()
# ç¯„ä¾‹å›å‚³æ ¼å¼ï¼š
#     {
#   "id": "chatcmpl-abc123",
#   "object": "chat.completion",
#   "choices": [
#     {
#       "index": 0,
#       "message": {
#         "role": "assistant",
#         "content": "æ‚¨å¥½ï¼Œæ­¡è¿å…‰è‡¨æœ¬é¤å»³ï¼"
#       },
#       "finish_reason": "stop"
#     }
#   ],
#   "usage": {
#     "prompt_tokens": 100,
#     "completion_tokens": 50,
#     "total_tokens": 150
#   }
# }
    
    print("\nğŸ§¾ [DEBUG] GPT å›è¦†å…§å®¹ï¼š")
    print(reply)
    print("--------------------\n")

    return reply

if __name__ == "__main__":
    # æ‰‹å‹•æ¸¬è©¦å€ï¼šè¼¸å…¥å•é¡Œèˆ‡ä½¿ç”¨è€… ID ä¾†æ¨¡æ“¬æŸ¥è©¢æµç¨‹
    query = input("è«‹è¼¸å…¥ä½ è¦æŸ¥è©¢çš„å•é¡Œï¼š\n> ")
    user_id = input("è«‹è¼¸å…¥æ¨¡æ“¬çš„ä½¿ç”¨è€… IDï¼š\n> ")

    answer = answer_query_secure(query, user_id)
    
    print("\nğŸ’¬ æœ€çµ‚å›è¦†å…§å®¹ï¼š")
    print(answer)


